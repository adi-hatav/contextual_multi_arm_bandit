Multi-Armed Bandit Algorithm with Adaptive Arm Deactivation for Enhanced Profitability

Multi-Armed Bandit (MAB) algorithm tailored for environments where arms may lose effectiveness if not chosen frequently.

* Exploration phase
* Use of Upper Confidence Bound
* Dynamic calculation of profit and loss in hand selection
